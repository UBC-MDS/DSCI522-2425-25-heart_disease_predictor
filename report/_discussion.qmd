# Discussion

## Summary of Findings: 

In this project, logistic regression and decision tree models were applied to classify individuals based on their likelihood of having heart disease. Both models successfully predicted heart disease diagnoses, with logistic regression outperforming decision trees in terms of interpretability and precision-recall performance.

The decision tree model  (@tbl-dst_model_results) achieved an accuracy of 74.44%, with a precision of 72.73% and recall of 83.33% for class 0, and a precision of 77.14% and recall of 64.29% for class 1. Its cross-validation results (@tbl-dst_cv_results) indicate potential overfitting, as training accuracy reached 100%, while test accuracy was 74.0%. The confusion matrix (@fig-conf-m-dt) revealed 83 true negatives and 70 true positives, but also 29 false positives and 25 false negatives, highlighting areas for improvement in generalization.

The logistic regression model(@tbl-lg_model_results), on the other hand, achieved higher overall performance with an accuracy of 84.44%. It demonstrated a balanced precision of 82.69% for class 0 and 86.84% for class 1, with recall values of 89.58% and 78.57%, respectively. The model's cross-validation results (@tbl-lg_cv_results) show that it generalizes well to unseen data without significant overfitting, with test accuracy at 82.6% and training accuracy at 87.3%. The confusion matrix @fig-conf-m-lg showed strong performance, with 95 true negatives and 76 true positives, and fewer misclassifications (17 false positives and 19 false negatives). Furthermore, the logistic regression coefficients @fig-coef-lg provided useful insights, highlighting the importance of features such as chest pain type, slope, and the number of vessels observed, which are crucial for clinical decision-making.


## Unexpected Findings: 

While many features, such as chest pain type and maximum heart rate, had high predictive power, some features demonstrated lower importance than expected. For instance, fasting blood sugar, a commonly discussed indicator in cardiovascular health, showed limited contribution in our models. This finding suggests that some clinical attributes may have less direct influence on heart disease risk than traditionally assumed or that their impact might be context-dependent.


## Future Work: 

There are several ways to improve upon the findings of this project:

1. Improving the Model: Trying advanced models like Random Forest or Gradient Boosting could help make predictions more accurate and reliable. These models work well with complex data by combining multiple decision-making techniques.

2. Exploring New Features: Adding more details to the data, like lifestyle habits (e.g., smoking, exercise) or family history, could make the model better at predicting heart disease.

3. Making the Model Explainable: Using tools like SHAP or LIME can help us understand why the model makes certain predictions. This is especially important for gaining trust in a healthcare setting.

4. Testing in the Real World: It would be valuable to test the model with real patient data in a clinical environment to see how it performs outside the lab.

5. Dealing with Uneven Data: If the dataset has many more people without heart disease than with it, methods like balancing the data or focusing on the underrepresented group can make the model fairer and more accurate.
