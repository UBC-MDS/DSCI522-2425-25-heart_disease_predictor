# Discussion

## Summary of Findings: 

In this project, logistic regression and decision tree models were applied to classify individuals based on their likelihood of having heart disease. Both models successfully predicted heart disease diagnoses, with logistic regression outperforming decision trees in terms of interpretability and precision-recall performance.

The decision tree model  (@tbl-dst_model_results) achieved an accuracy of `{python} dt_accuracy`%, with a precision of `{python} dt_precision_class_0`% and recall of `{python} dt_recall_class_0`% for class 0, and a precision of `{python} dt_precision_class_1`% and recall of `{python} dt_recall_class_1`% for class 1. Its cross-validation results (@tbl-dst_cv_results) indicate potential overfitting, as training accuracy reached `{python} dt_train_accuracy_cv`%, while test accuracy was `{python} dt_test_accuracy_cv` %. The confusion matrix (@fig-conf-m-dt) highlighted a reasonable balance between correctly classified positives and negatives. However, the results of both false positives and false negatives indicates that the model's generalization could be improved.


The logistic regression model(@tbl-lg_model_results), on the other hand, achieved higher overall performance with an accuracy of `{python} lg_accuracy`%. It demonstrated a balanced precision of `{python} lg_precision_class_0`% for class 0 and `{python} lg_precision_class_1`% for class 1, with recall values of `{python} lg_recall_class_0`% and `{python} lg_recall_class_1`%, respectively. The model's cross-validation results (@tbl-lg_cv_results) show that it generalizes well to unseen data without significant overfitting, with test accuracy at `{python} lg_test_accuracy_cv`% and training accuracy at `{python} lg_train_accuracy_cv`%. The confusion matrix (@fig-conf-m-lg) reflects strong model performance, mostly accurately classifying the majority of positive and negative cases. The occurrence of a few misclassifications indicates room for improvement, but overall, the model generalizes well. The logistic regression coefficients (@fig-coef-lg) further highlighted essential predictors, with features such as chest pain type, slope, and the number of vessels observed emerging as key indicators for clinical decision-making.




## Unexpected Findings: 

While many features, such as chest pain type and maximum heart rate, had high predictive power, some features demonstrated lower importance than expected. For instance, fasting blood sugar, a commonly discussed indicator in cardiovascular health, showed limited contribution in our models. This finding suggests that some clinical attributes may have less direct influence on heart disease risk than traditionally assumed or that their impact might be context-dependent.


## Future Work: 

There are several ways to improve upon the findings of this project:

1. Improving the Model: Trying advanced models like Random Forest or Gradient Boosting could help make predictions more accurate and reliable. These models work well with complex data by combining multiple decision-making techniques.

2. Exploring New Features: Adding more details to the data, like lifestyle habits (e.g., smoking, exercise) or family history, could make the model better at predicting heart disease.

3. Making the Model Explainable: Using tools like SHAP or LIME can help us understand why the model makes certain predictions. This is especially important for gaining trust in a healthcare setting.

4. Testing in the Real World: It would be valuable to test the model with real patient data in a clinical environment to see how it performs outside the lab.

5. Dealing with Uneven Data: If the dataset has many more people without heart disease than with it, methods like balancing the data or focusing on the underrepresented group can make the model fairer and more accurate.
